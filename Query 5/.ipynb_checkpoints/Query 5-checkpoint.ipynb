{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1efa4a-c1e8-4fff-9034-ef6c859c033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '8g', 'spark.executor.cores': '4'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>478</td><td>application_1764662801237_0480</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0480/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-11.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0480_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>479</td><td>application_1764662801237_0481</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0481/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-146.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0481_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"8g\",\n",
    "        \"spark.executor.cores\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a2f095-d6d2-49f7-bfa1-743e5f19fda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5901b196fc9840b1902393f7810d49f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_date, count, sum as _sum, corr, desc, lit, avg, regexp_replace, expr, upper, trim, split, explode, format_number\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType, FloatType\n",
    "import time\n",
    "\n",
    "# Sedona Imports\n",
    "from sedona.spark.SedonaContext import SedonaContext\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Query 5 execution 1\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.sedona_sql.io.SedonaSqlWrapper\") \\\n",
    "    .getOrCreate()\n",
    "spark = SedonaContext.create(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d243a6-da03-43e0-9728-46906e5030a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626505c0f4f843c687a09182913e45f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the data\n",
    "Crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", FloatType()),\n",
    "    StructField(\"LON\", FloatType()),\n",
    "])\n",
    "\n",
    "Income_schema = StructType([\n",
    "    StructField(\"Zip Code\", IntegerType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType()),\n",
    "])\n",
    "\n",
    "Crime_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                          header = True, \\\n",
    "                          schema = Crime_data_schema)\n",
    "\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\") \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "income_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\", \\\n",
    "                           header = True, \\\n",
    "                           schema = Income_schema, \\\n",
    "                           sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90c3d5e8-3532-4e1f-a014-69841e4a2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af8c3975f5942bdbb3f81fc3ea03eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "RangeJoin geometry_point#6445: geometry, geometry#268: geometry, WITHIN\n",
      ":- Project [DR_NO#200,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry_point#6445]\n",
      ":  +- Filter (((((isnotnull(LAT#226) AND isnotnull(LON#227)) AND NOT (LAT#226 = 0.0)) AND NOT (LON#227 = 0.0)) AND year(cast(gettimestamp(DATE OCC#202, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      ":     +- FileScan csv [DR_NO#200,DATE OCC#202,LAT#226,LON#227] Batched: false, DataFilters: [isnotnull(LAT#226), isnotnull(LON#227), NOT (LAT#226 = 0.0), NOT (LON#227 = 0.0), year(cast(gett..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))], ReadSchema: struct<DR_NO:int,DATE OCC:string,LAT:float,LON:float>\n",
      "+- *(1) Project [features#265.geometry AS geometry#268, features#265.properties.COMM AS COMM#6478, features#265.properties.POP20 AS POP20#6479L]\n",
      "   +- *(1) Filter isnotnull(features#265.geometry)\n",
      "      +- *(1) Generate explode(features#257), false, [features#265]\n",
      "         +- *(1) Filter ((size(features#257, true) > 0) AND isnotnull(features#257))\n",
      "            +- FileScan geojson [features#257] Batched: false, DataFilters: [(size(features#257, true) > 0), isnotnull(features#257)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "\n",
      "\n",
      "Execution Time: 40.7011 seconds\n",
      "Correlation (All Communities): -0.1651195871459252\n",
      "Correlation (Top 10 & Bottom 10 Income Areas): -0.22162106566579637\n",
      "\n",
      "--- Top 10 Wealthiest Areas Stats ---\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|             COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|PACIFIC PALISADES|           20952|           1362|     212115.0|                 0.03250|\n",
      "|      PLAYA VISTA|           16230|           1294|     166667.0|                 0.03986|\n",
      "|        BRENTWOOD|           30334|           2145|     143000.0|                 0.03536|\n",
      "|   MARINA DEL REY|           11373|             67|     137813.0|                 0.00295|\n",
      "| MARINA PENINSULA|            4903|            472|     137813.0|                 0.04813|\n",
      "|     PORTER RANCH|           35717|           1395|     130322.0|                 0.01953|\n",
      "|           ENCINO|           45045|           3893|     118878.0|                 0.04321|\n",
      "|      WESTCHESTER|           50760|           7592|     115943.0|                 0.07478|\n",
      "|    PLAYA DEL REY|            2958|            378|     110884.0|                 0.06389|\n",
      "|     CENTURY CITY|           13600|           1376|     109704.0|                 0.05059|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "\n",
      "\n",
      "--- Top 10 Poorest Areas Stats ---\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "|            COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "| HARVARD HEIGHTS|           15806|           1754|      41068.0|                 0.05549|\n",
      "|       KOREATOWN|           47297|           5330|      42990.5|                 0.05635|\n",
      "|        WESTLAKE|           56428|           7579|      43796.0|                 0.06716|\n",
      "|           WATTS|           42246|           4782|      46920.5|                 0.05660|\n",
      "|   BALDWIN HILLS|           30096|           3847|      49379.0|                 0.06391|\n",
      "|          LENNOX|           20323|             20|      50052.0|                 0.00049|\n",
      "|  EAST HOLLYWOOD|           24474|           2908|      50822.0|                 0.05941|\n",
      "|   PANORAMA CITY|           69747|           5112|      51485.0|                 0.03665|\n",
      "|    LEIMERT PARK|           15827|           2052|      52327.0|                 0.06483|\n",
      "|EAST LOS ANGELES|          118771|             54|      52878.5|                 0.00023|\n",
      "+----------------+----------------+---------------+-------------+------------------------+"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPARING CRIME DATA (2020-2021) ---\n",
    "# Filtering for years 2020-2021 Null Island (0,0) erasing\n",
    "crimes_filtered = Crime_df.filter((col(\"LAT\") != 0) & (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"Year\", year(to_date(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))) \\\n",
    "    .filter(col(\"Year\").isin([2020, 2021])) \\\n",
    "    .withColumn(\"geometry_point\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"DR_NO\", \"geometry_point\")\n",
    "\n",
    "# --- 2. PREPARING CENSUS DATA ---\n",
    "# We use POP20 (Population) and COMM (Location)\n",
    "census_blocks = blocks_df.select(\n",
    "    col(\"geometry\"),\n",
    "    col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    col(\"properties.POP20\").alias(\"POP20\")\n",
    ").filter(col(\"geometry\").isNotNull())\n",
    "\n",
    "# --- 3. PREPARING INCOME DATA ---\n",
    "income_clean = income_df.withColumn(\"Median_Income\", regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(IntegerType())) \\\n",
    "    .filter(col(\"Median_Income\").isNotNull()) \\\n",
    "    .withColumn(\"raw_comm\", col(\"Community\")) \\\n",
    "    .withColumn(\"comm_fixed_la\", regexp_replace(col(\"raw_comm\"), \"Los Angeles \\\\((.*?)\\\\)\", \"$1\")) \\\n",
    "    .withColumn(\"comm_final_str\", regexp_replace(col(\"comm_fixed_la\"), \"\\\\s*\\\\(.*?\\\\)\", \"\")) \\\n",
    "    .withColumn(\"comm_array\", split(col(\"comm_final_str\"), \",\")) \\\n",
    "    .select(explode(col(\"comm_array\")).alias(\"Community_Clean\"), col(\"Median_Income\")) \\\n",
    "    .withColumn(\"Community_Clean\", upper(trim(col(\"Community_Clean\")))) \\\n",
    "    .groupBy(\"Community_Clean\") \\\n",
    "    .agg(avg(\"Median_Income\").alias(\"Median_Income\"))\n",
    "\n",
    "# --- 4. SPATIAL JOIN (CRIMES + CENSUS) ---\n",
    "# We find in which Census block each crime is registered\n",
    "spatial_join = crimes_filtered.alias(\"crimes\").join(\n",
    "    census_blocks.alias(\"blocks\"),\n",
    "    expr(\"ST_Contains(blocks.geometry, crimes.geometry_point)\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# --- 5. AGGREGATIONS (PER COMMUNITY) ---\n",
    "# Step Α: Counting crimes per COMM\n",
    "crimes_per_comm = spatial_join.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(count(\"DR_NO\").alias(\"Total_Crimes_2y\"))\n",
    "\n",
    "# Step Β: Summing the population per COMM\n",
    "pop_per_comm = census_blocks.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(_sum(\"POP20\").alias(\"Total_Population\")) \\\n",
    "    .filter(col(\"Total_Population\") > 0)\n",
    "\n",
    "# Step C: Merging (Metrics + Income)\n",
    "# Join 'Community' and 'COMM'\n",
    "final_stats = pop_per_comm.join(crimes_per_comm, \"COMM_Clean\", \"inner\") \\\n",
    "    .join(income_clean, pop_per_comm.COMM_Clean == income_clean.Community_Clean, \"inner\") \\\n",
    "    .select(\n",
    "        col(\"COMM_Clean\").alias(\"COMM\"),\n",
    "        col(\"Total_Population\"),\n",
    "        col(\"Total_Crimes_2y\"),\n",
    "        col(\"Median_Income\")\n",
    "    )\n",
    "\n",
    "# --- 6. CALCULATE FINAL METRIC ---\n",
    "# Annual average crimes per person:\n",
    "# (Total_Crimes / 2) / Total_Population\n",
    "final_stats = final_stats.withColumn(\n",
    "    \"Crimes_Per_Person_Yearly\",\n",
    "    (col(\"Total_Crimes_2y\") / 2) / col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Join explain\n",
    "final_stats.explain()\n",
    "\n",
    "# Time Benchmarking\n",
    "start_time = time.time()\n",
    "total_records = final_stats.count()\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# --- 7. CORRELATION CALCULATIONS ---\n",
    "# 7.1 All Blocks\n",
    "corr_all = final_stats.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (All Communities): {corr_all}\")\n",
    "\n",
    "# 7.2 Top 10 and Bottom 10 based on income\n",
    "top_10 = final_stats.orderBy(col(\"Median_Income\").desc()).limit(10)\n",
    "bottom_10 = final_stats.orderBy(col(\"Median_Income\").asc()).limit(10)\n",
    "\n",
    "# Merge\n",
    "subset_extremes = top_10.union(bottom_10)\n",
    "\n",
    "corr_extremes = subset_extremes.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (Top 10 & Bottom 10 Income Areas): {corr_extremes}\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Top 10 Wealthiest Areas Stats ---\")\n",
    "top_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()\n",
    "print(\"\\n--- Top 10 Poorest Areas Stats ---\")\n",
    "bottom_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e09705-510b-425a-9ca9-8973a719a18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '4g', 'spark.executor.cores': '2'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>478</td><td>application_1764662801237_0480</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0480/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-11.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0480_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>482</td><td>application_1764662801237_0484</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0484/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-75.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0484_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>485</td><td>application_1764662801237_0487</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0487/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0487_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>486</td><td>application_1764662801237_0488</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0488/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0488_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"4g\",\n",
    "        \"spark.executor.cores\": \"2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669431d2-9e87-439d-8d9f-571db20d3303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>489</td><td>application_1764662801237_0491</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0491/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-133.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0491_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0cf2505cc748e0878551611584aa83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4038d11349884befbfb84042b291c1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_date, count, sum as _sum, corr, desc, lit, avg, regexp_replace, expr, upper, trim, split, explode, format_number\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType, FloatType\n",
    "import time\n",
    "\n",
    "# Sedona Imports\n",
    "from sedona.spark.SedonaContext import SedonaContext\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Query 5 execution 2\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.sedona_sql.io.SedonaSqlWrapper\") \\\n",
    "    .getOrCreate()\n",
    "spark = SedonaContext.create(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264144a5-f74e-4a2a-bbfb-3daaf7c21781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ba9cbdb65942a7ad5ccdeb6004f179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the data\n",
    "Crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", FloatType()),\n",
    "    StructField(\"LON\", FloatType()),\n",
    "])\n",
    "\n",
    "Income_schema = StructType([\n",
    "    StructField(\"Zip Code\", IntegerType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType()),\n",
    "])\n",
    "\n",
    "Crime_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                          header = True, \\\n",
    "                          schema = Crime_data_schema)\n",
    "\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\") \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "income_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\", \\\n",
    "                           header = True, \\\n",
    "                           schema = Income_schema, \\\n",
    "                           sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f66b46-cec2-47fb-b558-fdd11b41f5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6f25cadb414638861e6d8e8d94e861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "RangeJoin geometry_point#135: geometry, geometry#92: geometry, WITHIN\n",
      ":- Project [DR_NO#24,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry_point#135]\n",
      ":  +- Filter (((((isnotnull(LAT#50) AND isnotnull(LON#51)) AND NOT (LAT#50 = 0.0)) AND NOT (LON#51 = 0.0)) AND year(cast(gettimestamp(DATE OCC#26, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      ":     +- FileScan csv [DR_NO#24,DATE OCC#26,LAT#50,LON#51] Batched: false, DataFilters: [isnotnull(LAT#50), isnotnull(LON#51), NOT (LAT#50 = 0.0), NOT (LON#51 = 0.0), year(cast(gettimes..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))], ReadSchema: struct<DR_NO:int,DATE OCC:string,LAT:float,LON:float>\n",
      "+- *(1) Project [features#89.geometry AS geometry#92, features#89.properties.COMM AS COMM#168, features#89.properties.POP20 AS POP20#169L]\n",
      "   +- *(1) Filter isnotnull(features#89.geometry)\n",
      "      +- *(1) Generate explode(features#81), false, [features#89]\n",
      "         +- *(1) Filter ((size(features#81, true) > 0) AND isnotnull(features#81))\n",
      "            +- FileScan geojson [features#81] Batched: false, DataFilters: [(size(features#81, true) > 0), isnotnull(features#81)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "\n",
      "\n",
      "Execution Time: 28.0679 seconds\n",
      "Correlation (All Communities): -0.16511958714592506\n",
      "Correlation (Top 10 & Bottom 10 Income Areas): -0.22162106566579637\n",
      "\n",
      "--- Top 10 Wealthiest Areas Stats ---\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|             COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|PACIFIC PALISADES|           20952|           1362|     212115.0|                 0.03250|\n",
      "|      PLAYA VISTA|           16230|           1294|     166667.0|                 0.03986|\n",
      "|        BRENTWOOD|           30334|           2145|     143000.0|                 0.03536|\n",
      "|   MARINA DEL REY|           11373|             67|     137813.0|                 0.00295|\n",
      "| MARINA PENINSULA|            4903|            472|     137813.0|                 0.04813|\n",
      "|     PORTER RANCH|           35717|           1395|     130322.0|                 0.01953|\n",
      "|           ENCINO|           45045|           3893|     118878.0|                 0.04321|\n",
      "|      WESTCHESTER|           50760|           7592|     115943.0|                 0.07478|\n",
      "|    PLAYA DEL REY|            2958|            378|     110884.0|                 0.06389|\n",
      "|     CENTURY CITY|           13600|           1376|     109704.0|                 0.05059|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "\n",
      "\n",
      "--- Top 10 Poorest Areas Stats ---\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "|            COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "| HARVARD HEIGHTS|           15806|           1754|      41068.0|                 0.05549|\n",
      "|       KOREATOWN|           47297|           5330|      42990.5|                 0.05635|\n",
      "|        WESTLAKE|           56428|           7579|      43796.0|                 0.06716|\n",
      "|           WATTS|           42246|           4782|      46920.5|                 0.05660|\n",
      "|   BALDWIN HILLS|           30096|           3847|      49379.0|                 0.06391|\n",
      "|          LENNOX|           20323|             20|      50052.0|                 0.00049|\n",
      "|  EAST HOLLYWOOD|           24474|           2908|      50822.0|                 0.05941|\n",
      "|   PANORAMA CITY|           69747|           5112|      51485.0|                 0.03665|\n",
      "|    LEIMERT PARK|           15827|           2052|      52327.0|                 0.06483|\n",
      "|EAST LOS ANGELES|          118771|             54|      52878.5|                 0.00023|\n",
      "+----------------+----------------+---------------+-------------+------------------------+"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPARING CRIME DATA (2020-2021) ---\n",
    "# Filtering for years 2020-2021 Null Island (0,0) erasing\n",
    "crimes_filtered = Crime_df.filter((col(\"LAT\") != 0) & (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"Year\", year(to_date(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))) \\\n",
    "    .filter(col(\"Year\").isin([2020, 2021])) \\\n",
    "    .withColumn(\"geometry_point\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"DR_NO\", \"geometry_point\")\n",
    "\n",
    "# --- 2. PREPARING CENSUS DATA ---\n",
    "# We use POP20 (Population) and COMM (Location)\n",
    "census_blocks = blocks_df.select(\n",
    "    col(\"geometry\"),\n",
    "    col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    col(\"properties.POP20\").alias(\"POP20\")\n",
    ").filter(col(\"geometry\").isNotNull())\n",
    "\n",
    "# --- 3. PREPARING INCOME DATA ---\n",
    "income_clean = income_df.withColumn(\"Median_Income\", regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(IntegerType())) \\\n",
    "    .filter(col(\"Median_Income\").isNotNull()) \\\n",
    "    .withColumn(\"raw_comm\", col(\"Community\")) \\\n",
    "    .withColumn(\"comm_fixed_la\", regexp_replace(col(\"raw_comm\"), \"Los Angeles \\\\((.*?)\\\\)\", \"$1\")) \\\n",
    "    .withColumn(\"comm_final_str\", regexp_replace(col(\"comm_fixed_la\"), \"\\\\s*\\\\(.*?\\\\)\", \"\")) \\\n",
    "    .withColumn(\"comm_array\", split(col(\"comm_final_str\"), \",\")) \\\n",
    "    .select(explode(col(\"comm_array\")).alias(\"Community_Clean\"), col(\"Median_Income\")) \\\n",
    "    .withColumn(\"Community_Clean\", upper(trim(col(\"Community_Clean\")))) \\\n",
    "    .groupBy(\"Community_Clean\") \\\n",
    "    .agg(avg(\"Median_Income\").alias(\"Median_Income\"))\n",
    "\n",
    "# --- 4. SPATIAL JOIN (CRIMES + CENSUS) ---\n",
    "# We find in which Census block each crime is registered\n",
    "spatial_join = crimes_filtered.alias(\"crimes\").join(\n",
    "    census_blocks.alias(\"blocks\"),\n",
    "    expr(\"ST_Contains(blocks.geometry, crimes.geometry_point)\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# --- 5. AGGREGATIONS (PER COMMUNITY) ---\n",
    "# Step Α: Counting crimes per COMM\n",
    "crimes_per_comm = spatial_join.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(count(\"DR_NO\").alias(\"Total_Crimes_2y\"))\n",
    "\n",
    "# Step Β: Summing the population per COMM\n",
    "pop_per_comm = census_blocks.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(_sum(\"POP20\").alias(\"Total_Population\")) \\\n",
    "    .filter(col(\"Total_Population\") > 0)\n",
    "\n",
    "# Step C: Merging (Metrics + Income)\n",
    "# Join 'Community' and 'COMM'\n",
    "final_stats = pop_per_comm.join(crimes_per_comm, \"COMM_Clean\", \"inner\") \\\n",
    "    .join(income_clean, pop_per_comm.COMM_Clean == income_clean.Community_Clean, \"inner\") \\\n",
    "    .select(\n",
    "        col(\"COMM_Clean\").alias(\"COMM\"),\n",
    "        col(\"Total_Population\"),\n",
    "        col(\"Total_Crimes_2y\"),\n",
    "        col(\"Median_Income\")\n",
    "    )\n",
    "\n",
    "# --- 6. CALCULATE FINAL METRIC ---\n",
    "# Annual average crimes per person:\n",
    "# (Total_Crimes / 2) / Total_Population\n",
    "final_stats = final_stats.withColumn(\n",
    "    \"Crimes_Per_Person_Yearly\",\n",
    "    (col(\"Total_Crimes_2y\") / 2) / col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Join explain\n",
    "final_stats.explain()\n",
    "\n",
    "# Time Benchmarking\n",
    "start_time = time.time()\n",
    "total_records = final_stats.count()\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# --- 7. CORRELATION CALCULATIONS ---\n",
    "# 7.1 All Blocks\n",
    "corr_all = final_stats.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (All Communities): {corr_all}\")\n",
    "\n",
    "# 7.2 Top 10 and Bottom 10 based on income\n",
    "top_10 = final_stats.orderBy(col(\"Median_Income\").desc()).limit(10)\n",
    "bottom_10 = final_stats.orderBy(col(\"Median_Income\").asc()).limit(10)\n",
    "\n",
    "# Merge\n",
    "subset_extremes = top_10.union(bottom_10)\n",
    "\n",
    "corr_extremes = subset_extremes.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (Top 10 & Bottom 10 Income Areas): {corr_extremes}\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Top 10 Wealthiest Areas Stats ---\")\n",
    "top_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()\n",
    "print(\"\\n--- Top 10 Poorest Areas Stats ---\")\n",
    "bottom_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7414931-66ec-476b-a1b8-ce4f1d9f91c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '8', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>478</td><td>application_1764662801237_0480</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0480/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-11.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0480_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>482</td><td>application_1764662801237_0484</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0484/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-75.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0484_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>485</td><td>application_1764662801237_0487</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0487/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0487_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>486</td><td>application_1764662801237_0488</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0488/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0488_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"8\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a752f20a-b0dd-43af-ad93-09156cee9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>488</td><td>application_1764662801237_0490</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0490/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0490_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d68fadfd2304637895ca164733fc8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0969aef22f743abb84b0758f25ec7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_date, count, sum as _sum, corr, desc, lit, avg, regexp_replace, expr, upper, trim, split, explode, format_number\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType, FloatType\n",
    "import time\n",
    "\n",
    "# Sedona Imports\n",
    "from sedona.spark.SedonaContext import SedonaContext\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Query 5 execution 3\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.sedona_sql.io.SedonaSqlWrapper\") \\\n",
    "    .getOrCreate()\n",
    "spark = SedonaContext.create(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92e0156-8c45-44bf-9db5-44021f8bed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6ddcd6fb6847bd9a98d9577d526a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the data\n",
    "Crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", FloatType()),\n",
    "    StructField(\"LON\", FloatType()),\n",
    "])\n",
    "\n",
    "Income_schema = StructType([\n",
    "    StructField(\"Zip Code\", IntegerType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType()),\n",
    "])\n",
    "\n",
    "Crime_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                          header = True, \\\n",
    "                          schema = Crime_data_schema)\n",
    "\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\") \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "income_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\", \\\n",
    "                           header = True, \\\n",
    "                           schema = Income_schema, \\\n",
    "                           sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d461d5-5fbd-4cdf-bfce-901f256e0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b073dd095cf4f6291482f9baee87c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "RangeJoin geometry_point#1149: geometry, geometry#92: geometry, WITHIN\n",
      ":- Project [DR_NO#24,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry_point#1149]\n",
      ":  +- Filter (((((isnotnull(LAT#50) AND isnotnull(LON#51)) AND NOT (LAT#50 = 0.0)) AND NOT (LON#51 = 0.0)) AND year(cast(gettimestamp(DATE OCC#26, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      ":     +- FileScan csv [DR_NO#24,DATE OCC#26,LAT#50,LON#51] Batched: false, DataFilters: [isnotnull(LAT#50), isnotnull(LON#51), NOT (LAT#50 = 0.0), NOT (LON#51 = 0.0), year(cast(gettimes..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))], ReadSchema: struct<DR_NO:int,DATE OCC:string,LAT:float,LON:float>\n",
      "+- *(1) Project [features#89.geometry AS geometry#92, features#89.properties.COMM AS COMM#1182, features#89.properties.POP20 AS POP20#1183L]\n",
      "   +- *(1) Filter isnotnull(features#89.geometry)\n",
      "      +- *(1) Generate explode(features#81), false, [features#89]\n",
      "         +- *(1) Filter ((size(features#81, true) > 0) AND isnotnull(features#81))\n",
      "            +- FileScan geojson [features#81] Batched: false, DataFilters: [(size(features#81, true) > 0), isnotnull(features#81)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "\n",
      "\n",
      "Execution Time: 41.6700 seconds\n",
      "Correlation (All Communities): -0.16511958714592506\n",
      "Correlation (Top 10 & Bottom 10 Income Areas): -0.22162106566579653\n",
      "\n",
      "--- Top 10 Wealthiest Areas Stats ---\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|             COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|PACIFIC PALISADES|           20952|           1362|     212115.0|                 0.03250|\n",
      "|      PLAYA VISTA|           16230|           1294|     166667.0|                 0.03986|\n",
      "|        BRENTWOOD|           30334|           2145|     143000.0|                 0.03536|\n",
      "|   MARINA DEL REY|           11373|             67|     137813.0|                 0.00295|\n",
      "| MARINA PENINSULA|            4903|            472|     137813.0|                 0.04813|\n",
      "|     PORTER RANCH|           35717|           1395|     130322.0|                 0.01953|\n",
      "|           ENCINO|           45045|           3893|     118878.0|                 0.04321|\n",
      "|      WESTCHESTER|           50760|           7592|     115943.0|                 0.07478|\n",
      "|    PLAYA DEL REY|            2958|            378|     110884.0|                 0.06389|\n",
      "|     CENTURY CITY|           13600|           1376|     109704.0|                 0.05059|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "\n",
      "\n",
      "--- Top 10 Poorest Areas Stats ---\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "|            COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "| HARVARD HEIGHTS|           15806|           1754|      41068.0|                 0.05549|\n",
      "|       KOREATOWN|           47297|           5330|      42990.5|                 0.05635|\n",
      "|        WESTLAKE|           56428|           7579|      43796.0|                 0.06716|\n",
      "|           WATTS|           42246|           4782|      46920.5|                 0.05660|\n",
      "|   BALDWIN HILLS|           30096|           3847|      49379.0|                 0.06391|\n",
      "|          LENNOX|           20323|             20|      50052.0|                 0.00049|\n",
      "|  EAST HOLLYWOOD|           24474|           2908|      50822.0|                 0.05941|\n",
      "|   PANORAMA CITY|           69747|           5112|      51485.0|                 0.03665|\n",
      "|    LEIMERT PARK|           15827|           2052|      52327.0|                 0.06483|\n",
      "|EAST LOS ANGELES|          118771|             54|      52878.5|                 0.00023|\n",
      "+----------------+----------------+---------------+-------------+------------------------+"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPARING CRIME DATA (2020-2021) ---\n",
    "# Filtering for years 2020-2021 Null Island (0,0) erasing\n",
    "crimes_filtered = Crime_df.filter((col(\"LAT\") != 0) & (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"Year\", year(to_date(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))) \\\n",
    "    .filter(col(\"Year\").isin([2020, 2021])) \\\n",
    "    .withColumn(\"geometry_point\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"DR_NO\", \"geometry_point\")\n",
    "\n",
    "# --- 2. PREPARING CENSUS DATA ---\n",
    "# We use POP20 (Population) and COMM (Location)\n",
    "census_blocks = blocks_df.select(\n",
    "    col(\"geometry\"),\n",
    "    col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    col(\"properties.POP20\").alias(\"POP20\")\n",
    ").filter(col(\"geometry\").isNotNull())\n",
    "\n",
    "# --- 3. PREPARING INCOME DATA ---\n",
    "income_clean = income_df.withColumn(\"Median_Income\", regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(IntegerType())) \\\n",
    "    .filter(col(\"Median_Income\").isNotNull()) \\\n",
    "    .withColumn(\"raw_comm\", col(\"Community\")) \\\n",
    "    .withColumn(\"comm_fixed_la\", regexp_replace(col(\"raw_comm\"), \"Los Angeles \\\\((.*?)\\\\)\", \"$1\")) \\\n",
    "    .withColumn(\"comm_final_str\", regexp_replace(col(\"comm_fixed_la\"), \"\\\\s*\\\\(.*?\\\\)\", \"\")) \\\n",
    "    .withColumn(\"comm_array\", split(col(\"comm_final_str\"), \",\")) \\\n",
    "    .select(explode(col(\"comm_array\")).alias(\"Community_Clean\"), col(\"Median_Income\")) \\\n",
    "    .withColumn(\"Community_Clean\", upper(trim(col(\"Community_Clean\")))) \\\n",
    "    .groupBy(\"Community_Clean\") \\\n",
    "    .agg(avg(\"Median_Income\").alias(\"Median_Income\"))\n",
    "\n",
    "# --- 4. SPATIAL JOIN (CRIMES + CENSUS) ---\n",
    "# We find in which Census block each crime is registered\n",
    "spatial_join = crimes_filtered.alias(\"crimes\").join(\n",
    "    census_blocks.alias(\"blocks\"),\n",
    "    expr(\"ST_Contains(blocks.geometry, crimes.geometry_point)\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# --- 5. AGGREGATIONS (PER COMMUNITY) ---\n",
    "# Step Α: Counting crimes per COMM\n",
    "crimes_per_comm = spatial_join.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(count(\"DR_NO\").alias(\"Total_Crimes_2y\"))\n",
    "\n",
    "# Step Β: Summing the population per COMM\n",
    "pop_per_comm = census_blocks.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(_sum(\"POP20\").alias(\"Total_Population\")) \\\n",
    "    .filter(col(\"Total_Population\") > 0)\n",
    "\n",
    "# Step C: Merging (Metrics + Income)\n",
    "# Join 'Community' and 'COMM'\n",
    "final_stats = pop_per_comm.join(crimes_per_comm, \"COMM_Clean\", \"inner\") \\\n",
    "    .join(income_clean, pop_per_comm.COMM_Clean == income_clean.Community_Clean, \"inner\") \\\n",
    "    .select(\n",
    "        col(\"COMM_Clean\").alias(\"COMM\"),\n",
    "        col(\"Total_Population\"),\n",
    "        col(\"Total_Crimes_2y\"),\n",
    "        col(\"Median_Income\")\n",
    "    )\n",
    "\n",
    "# --- 6. CALCULATE FINAL METRIC ---\n",
    "# Annual average crimes per person:\n",
    "# (Total_Crimes / 2) / Total_Population\n",
    "final_stats = final_stats.withColumn(\n",
    "    \"Crimes_Per_Person_Yearly\",\n",
    "    (col(\"Total_Crimes_2y\") / 2) / col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Join explain\n",
    "final_stats.explain()\n",
    "\n",
    "# Time Benchmarking\n",
    "start_time = time.time()\n",
    "total_records = final_stats.count()\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# --- 7. CORRELATION CALCULATIONS ---\n",
    "# 7.1 All Blocks\n",
    "corr_all = final_stats.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (All Communities): {corr_all}\")\n",
    "\n",
    "# 7.2 Top 10 and Bottom 10 based on income\n",
    "top_10 = final_stats.orderBy(col(\"Median_Income\").desc()).limit(10)\n",
    "bottom_10 = final_stats.orderBy(col(\"Median_Income\").asc()).limit(10)\n",
    "\n",
    "# Merge\n",
    "subset_extremes = top_10.union(bottom_10)\n",
    "\n",
    "corr_extremes = subset_extremes.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (Top 10 & Bottom 10 Income Areas): {corr_extremes}\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Top 10 Wealthiest Areas Stats ---\")\n",
    "top_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()\n",
    "print(\"\\n--- Top 10 Poorest Areas Stats ---\")\n",
    "bottom_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
