{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1efa4a-c1e8-4fff-9034-ef6c859c033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '8g', 'spark.executor.cores': '4'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>478</td><td>application_1764662801237_0480</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0480/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-11.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0480_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>482</td><td>application_1764662801237_0484</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0484/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-75.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0484_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>485</td><td>application_1764662801237_0487</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0487/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0487_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>486</td><td>application_1764662801237_0488</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0488/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0488_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"8g\",\n",
    "        \"spark.executor.cores\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a2f095-d6d2-49f7-bfa1-743e5f19fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>490</td><td>application_1764662801237_0492</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0492/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-92.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0492_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c16ca9cbac8497bb5fa83d181fc5d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fda989b4034d40855905cac6a60f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_date, count, sum as _sum, corr, desc, lit, avg, regexp_replace, expr, upper, trim, split, explode, format_number\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType, FloatType\n",
    "import time\n",
    "\n",
    "# Sedona Imports\n",
    "from sedona.spark.SedonaContext import SedonaContext\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Query 5 execution 1\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.sedona_sql.io.SedonaSqlWrapper\") \\\n",
    "    .getOrCreate()\n",
    "spark = SedonaContext.create(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d243a6-da03-43e0-9728-46906e5030a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35c49a3e3a9494aa4a9e7b3db94c8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the data\n",
    "Crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", FloatType()),\n",
    "    StructField(\"LON\", FloatType()),\n",
    "])\n",
    "\n",
    "Income_schema = StructType([\n",
    "    StructField(\"Zip Code\", IntegerType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType()),\n",
    "])\n",
    "\n",
    "Crime_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                          header = True, \\\n",
    "                          schema = Crime_data_schema)\n",
    "\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\") \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "income_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\", \\\n",
    "                           header = True, \\\n",
    "                           schema = Income_schema, \\\n",
    "                           sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c3d5e8-3532-4e1f-a014-69841e4a2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e42326629a4fa0853098d926b9df1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [COMM_Clean#251 AS COMM#282, Total_Population#261L, Total_Crimes_2y#248L, Median_Income#221, ((cast(Total_Crimes_2y#248L as double) / 2.0) / cast(Total_Population#261L as double)) AS Crimes_Per_Person_Yearly#287]\n",
      "   +- BroadcastHashJoin [COMM_Clean#251], [Community_Clean#215], Inner, BuildRight, false\n",
      "      :- Project [COMM_Clean#251, Total_Population#261L, Total_Crimes_2y#248L]\n",
      "      :  +- BroadcastHashJoin [COMM_Clean#251], [COMM_Clean#234], Inner, BuildLeft, false\n",
      "      :     :- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=190]\n",
      "      :     :  +- Filter (isnotnull(Total_Population#261L) AND (Total_Population#261L > 0))\n",
      "      :     :     +- HashAggregate(keys=[COMM_Clean#251], functions=[sum(POP20#169L)], schema specialized)\n",
      "      :     :        +- Exchange hashpartitioning(COMM_Clean#251, 1000), ENSURE_REQUIREMENTS, [plan_id=184]\n",
      "      :     :           +- HashAggregate(keys=[COMM_Clean#251], functions=[partial_sum(POP20#169L)], schema specialized)\n",
      "      :     :              +- Project [features#89.properties.POP20 AS POP20#169L, upper(trim(features#89.properties.COMM, None)) AS COMM_Clean#251]\n",
      "      :     :                 +- Filter (isnotnull(features#89.geometry) AND isnotnull(upper(trim(features#89.properties.COMM, None))))\n",
      "      :     :                    +- Generate explode(features#81), false, [features#89]\n",
      "      :     :                       +- Filter ((size(features#81, true) > 0) AND isnotnull(features#81))\n",
      "      :     :                          +- FileScan geojson [features#81] Batched: false, DataFilters: [(size(features#81, true) > 0), isnotnull(features#81)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      :     +- HashAggregate(keys=[COMM_Clean#234], functions=[count(DR_NO#24)], schema specialized)\n",
      "      :        +- Exchange hashpartitioning(COMM_Clean#234, 1000), ENSURE_REQUIREMENTS, [plan_id=187]\n",
      "      :           +- HashAggregate(keys=[COMM_Clean#234], functions=[partial_count(DR_NO#24)], schema specialized)\n",
      "      :              +- Project [DR_NO#24, upper(trim(COMM#168, None)) AS COMM_Clean#234]\n",
      "      :                 +- RangeJoin geometry_point#135: geometry, geometry#92: geometry, WITHIN\n",
      "      :                    :- Project [DR_NO#24,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry_point#135]\n",
      "      :                    :  +- Filter (((((isnotnull(LAT#50) AND isnotnull(LON#51)) AND NOT (LAT#50 = 0.0)) AND NOT (LON#51 = 0.0)) AND year(cast(gettimestamp(DATE OCC#26, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "      :                    :     +- FileScan csv [DR_NO#24,DATE OCC#26,LAT#50,LON#51] Batched: false, DataFilters: [isnotnull(LAT#50), isnotnull(LON#51), NOT (LAT#50 = 0.0), NOT (LON#51 = 0.0), year(cast(gettimes..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))], ReadSchema: struct<DR_NO:int,DATE OCC:string,LAT:float,LON:float>\n",
      "      :                    +- Project [features#89.geometry AS geometry#92, features#89.properties.COMM AS COMM#168]\n",
      "      :                       +- Filter (isnotnull(features#89.geometry) AND isnotnull(upper(trim(features#89.properties.COMM, None))))\n",
      "      :                          +- Generate explode(features#265), false, [features#89]\n",
      "      :                             +- Filter ((size(features#265, true) > 0) AND isnotnull(features#265))\n",
      "      :                                +- FileScan geojson [features#265] Batched: false, DataFilters: [(size(features#265, true) > 0), isnotnull(features#265)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=196]\n",
      "         +- HashAggregate(keys=[Community_Clean#215], functions=[avg(Median_Income#175)], schema specialized)\n",
      "            +- Exchange hashpartitioning(Community_Clean#215, 1000), ENSURE_REQUIREMENTS, [plan_id=193]\n",
      "               +- HashAggregate(keys=[Community_Clean#215], functions=[partial_avg(Median_Income#175)], schema specialized)\n",
      "                  +- Project [upper(trim(Community_Clean#212, None)) AS Community_Clean#215, Median_Income#175]\n",
      "                     +- Generate explode(comm_array#202), [Median_Income#175], false, [Community_Clean#212]\n",
      "                        +- Project [cast(regexp_replace(Estimated Median Income#100, [$,], , 1) as int) AS Median_Income#175, split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1) AS comm_array#202]\n",
      "                           +- Filter (((isnotnull(Estimated Median Income#100) AND isnotnull(cast(regexp_replace(Estimated Median Income#100, [$,], , 1) as int))) AND (size(split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1), true) > 0)) AND isnotnull(split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1)))\n",
      "                              +- FileScan csv [Community#99,Estimated Median Income#100] Batched: false, DataFilters: [isnotnull(Estimated Median Income#100), isnotnull(cast(regexp_replace(Estimated Median Income#10..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [IsNotNull(Estimated Median Income)], ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "Execution Time: 24.8516 seconds\n",
      "Correlation (All Communities): -0.165119587145925\n",
      "Correlation (Top 10 & Bottom 10 Income Areas): -0.22162106566579637\n",
      "\n",
      "--- Top 10 Wealthiest Areas Stats ---\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|             COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|PACIFIC PALISADES|           20952|           1362|     212115.0|                 0.03250|\n",
      "|      PLAYA VISTA|           16230|           1294|     166667.0|                 0.03986|\n",
      "|        BRENTWOOD|           30334|           2145|     143000.0|                 0.03536|\n",
      "|   MARINA DEL REY|           11373|             67|     137813.0|                 0.00295|\n",
      "| MARINA PENINSULA|            4903|            472|     137813.0|                 0.04813|\n",
      "|     PORTER RANCH|           35717|           1395|     130322.0|                 0.01953|\n",
      "|           ENCINO|           45045|           3893|     118878.0|                 0.04321|\n",
      "|      WESTCHESTER|           50760|           7592|     115943.0|                 0.07478|\n",
      "|    PLAYA DEL REY|            2958|            378|     110884.0|                 0.06389|\n",
      "|     CENTURY CITY|           13600|           1376|     109704.0|                 0.05059|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "\n",
      "\n",
      "--- Top 10 Poorest Areas Stats ---\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "|            COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "| HARVARD HEIGHTS|           15806|           1754|      41068.0|                 0.05549|\n",
      "|       KOREATOWN|           47297|           5330|      42990.5|                 0.05635|\n",
      "|        WESTLAKE|           56428|           7579|      43796.0|                 0.06716|\n",
      "|           WATTS|           42246|           4782|      46920.5|                 0.05660|\n",
      "|   BALDWIN HILLS|           30096|           3847|      49379.0|                 0.06391|\n",
      "|          LENNOX|           20323|             20|      50052.0|                 0.00049|\n",
      "|  EAST HOLLYWOOD|           24474|           2908|      50822.0|                 0.05941|\n",
      "|   PANORAMA CITY|           69747|           5112|      51485.0|                 0.03665|\n",
      "|    LEIMERT PARK|           15827|           2052|      52327.0|                 0.06483|\n",
      "|EAST LOS ANGELES|          118771|             54|      52878.5|                 0.00023|\n",
      "+----------------+----------------+---------------+-------------+------------------------+"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPARING CRIME DATA (2020-2021) ---\n",
    "# Filtering for years 2020-2021 Null Island (0,0) erasing\n",
    "crimes_filtered = Crime_df.filter((col(\"LAT\") != 0) & (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"Year\", year(to_date(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))) \\\n",
    "    .filter(col(\"Year\").isin([2020, 2021])) \\\n",
    "    .withColumn(\"geometry_point\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"DR_NO\", \"geometry_point\")\n",
    "\n",
    "# --- 2. PREPARING CENSUS DATA ---\n",
    "# We use POP20 (Population) and COMM (Location)\n",
    "census_blocks = blocks_df.select(\n",
    "    col(\"geometry\"),\n",
    "    col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    col(\"properties.POP20\").alias(\"POP20\")\n",
    ").filter(col(\"geometry\").isNotNull())\n",
    "\n",
    "# --- 3. PREPARING INCOME DATA ---\n",
    "income_clean = income_df.withColumn(\"Median_Income\", regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(IntegerType())) \\\n",
    "    .filter(col(\"Median_Income\").isNotNull()) \\\n",
    "    .withColumn(\"raw_comm\", col(\"Community\")) \\\n",
    "    .withColumn(\"comm_fixed_la\", regexp_replace(col(\"raw_comm\"), \"Los Angeles \\\\((.*?)\\\\)\", \"$1\")) \\\n",
    "    .withColumn(\"comm_final_str\", regexp_replace(col(\"comm_fixed_la\"), \"\\\\s*\\\\(.*?\\\\)\", \"\")) \\\n",
    "    .withColumn(\"comm_array\", split(col(\"comm_final_str\"), \",\")) \\\n",
    "    .select(explode(col(\"comm_array\")).alias(\"Community_Clean\"), col(\"Median_Income\")) \\\n",
    "    .withColumn(\"Community_Clean\", upper(trim(col(\"Community_Clean\")))) \\\n",
    "    .groupBy(\"Community_Clean\") \\\n",
    "    .agg(avg(\"Median_Income\").alias(\"Median_Income\"))\n",
    "\n",
    "# --- 4. SPATIAL JOIN (CRIMES + CENSUS) ---\n",
    "# We find in which Census block each crime is registered\n",
    "spatial_join = crimes_filtered.alias(\"crimes\").join(\n",
    "    census_blocks.alias(\"blocks\"),\n",
    "    expr(\"ST_Contains(blocks.geometry, crimes.geometry_point)\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# --- 5. AGGREGATIONS (PER COMMUNITY) ---\n",
    "# Step Α: Counting crimes per COMM\n",
    "crimes_per_comm = spatial_join.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(count(\"DR_NO\").alias(\"Total_Crimes_2y\"))\n",
    "\n",
    "# Step Β: Summing the population per COMM\n",
    "pop_per_comm = census_blocks.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(_sum(\"POP20\").alias(\"Total_Population\")) \\\n",
    "    .filter(col(\"Total_Population\") > 0)\n",
    "\n",
    "# Step C: Merging (Metrics + Income)\n",
    "# Join 'Community' and 'COMM'\n",
    "final_stats = pop_per_comm.join(crimes_per_comm, \"COMM_Clean\", \"inner\") \\\n",
    "    .join(income_clean, pop_per_comm.COMM_Clean == income_clean.Community_Clean, \"inner\") \\\n",
    "    .select(\n",
    "        col(\"COMM_Clean\").alias(\"COMM\"),\n",
    "        col(\"Total_Population\"),\n",
    "        col(\"Total_Crimes_2y\"),\n",
    "        col(\"Median_Income\")\n",
    "    )\n",
    "\n",
    "# --- 6. CALCULATE FINAL METRIC ---\n",
    "# Annual average crimes per person:\n",
    "# (Total_Crimes / 2) / Total_Population\n",
    "final_stats = final_stats.withColumn(\n",
    "    \"Crimes_Per_Person_Yearly\",\n",
    "    (col(\"Total_Crimes_2y\") / 2) / col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Join explain\n",
    "final_stats.explain()\n",
    "\n",
    "# Time Benchmarking\n",
    "start_time = time.time()\n",
    "total_records = final_stats.count()\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# --- 7. CORRELATION CALCULATIONS ---\n",
    "# 7.1 All Blocks\n",
    "corr_all = final_stats.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (All Communities): {corr_all}\")\n",
    "\n",
    "# 7.2 Top 10 and Bottom 10 based on income\n",
    "top_10 = final_stats.orderBy(col(\"Median_Income\").desc()).limit(10)\n",
    "bottom_10 = final_stats.orderBy(col(\"Median_Income\").asc()).limit(10)\n",
    "\n",
    "# Merge\n",
    "subset_extremes = top_10.union(bottom_10)\n",
    "\n",
    "corr_extremes = subset_extremes.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (Top 10 & Bottom 10 Income Areas): {corr_extremes}\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Top 10 Wealthiest Areas Stats ---\")\n",
    "top_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()\n",
    "print(\"\\n--- Top 10 Poorest Areas Stats ---\")\n",
    "bottom_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e09705-510b-425a-9ca9-8973a719a18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '4g', 'spark.executor.cores': '2'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>478</td><td>application_1764662801237_0480</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0480/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-11.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0480_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>482</td><td>application_1764662801237_0484</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0484/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-75.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0484_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>485</td><td>application_1764662801237_0487</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0487/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0487_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>486</td><td>application_1764662801237_0488</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0488/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0488_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"4g\",\n",
    "        \"spark.executor.cores\": \"2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669431d2-9e87-439d-8d9f-571db20d3303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>491</td><td>application_1764662801237_0493</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0493/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-92.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0493_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff2eca684a94ba6b6dac0782a479f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1684da3923664348964ce9f01ff12c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_date, count, sum as _sum, corr, desc, lit, avg, regexp_replace, expr, upper, trim, split, explode, format_number\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType, FloatType\n",
    "import time\n",
    "\n",
    "# Sedona Imports\n",
    "from sedona.spark.SedonaContext import SedonaContext\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Query 5 execution 2\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.sedona_sql.io.SedonaSqlWrapper\") \\\n",
    "    .getOrCreate()\n",
    "spark = SedonaContext.create(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264144a5-f74e-4a2a-bbfb-3daaf7c21781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9212010efe4cf2b62e707cbf2d9054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the data\n",
    "Crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", FloatType()),\n",
    "    StructField(\"LON\", FloatType()),\n",
    "])\n",
    "\n",
    "Income_schema = StructType([\n",
    "    StructField(\"Zip Code\", IntegerType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType()),\n",
    "])\n",
    "\n",
    "Crime_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                          header = True, \\\n",
    "                          schema = Crime_data_schema)\n",
    "\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\") \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "income_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\", \\\n",
    "                           header = True, \\\n",
    "                           schema = Income_schema, \\\n",
    "                           sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f66b46-cec2-47fb-b558-fdd11b41f5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de4978a03ad4107a6ca4cf0ee845d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [COMM_Clean#251 AS COMM#282, Total_Population#261L, Total_Crimes_2y#248L, Median_Income#221, ((cast(Total_Crimes_2y#248L as double) / 2.0) / cast(Total_Population#261L as double)) AS Crimes_Per_Person_Yearly#287]\n",
      "   +- BroadcastHashJoin [COMM_Clean#251], [Community_Clean#215], Inner, BuildRight, false\n",
      "      :- Project [COMM_Clean#251, Total_Population#261L, Total_Crimes_2y#248L]\n",
      "      :  +- BroadcastHashJoin [COMM_Clean#251], [COMM_Clean#234], Inner, BuildLeft, false\n",
      "      :     :- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=190]\n",
      "      :     :  +- Filter (isnotnull(Total_Population#261L) AND (Total_Population#261L > 0))\n",
      "      :     :     +- HashAggregate(keys=[COMM_Clean#251], functions=[sum(POP20#169L)], schema specialized)\n",
      "      :     :        +- Exchange hashpartitioning(COMM_Clean#251, 1000), ENSURE_REQUIREMENTS, [plan_id=184]\n",
      "      :     :           +- HashAggregate(keys=[COMM_Clean#251], functions=[partial_sum(POP20#169L)], schema specialized)\n",
      "      :     :              +- Project [features#89.properties.POP20 AS POP20#169L, upper(trim(features#89.properties.COMM, None)) AS COMM_Clean#251]\n",
      "      :     :                 +- Filter (isnotnull(features#89.geometry) AND isnotnull(upper(trim(features#89.properties.COMM, None))))\n",
      "      :     :                    +- Generate explode(features#81), false, [features#89]\n",
      "      :     :                       +- Filter ((size(features#81, true) > 0) AND isnotnull(features#81))\n",
      "      :     :                          +- FileScan geojson [features#81] Batched: false, DataFilters: [(size(features#81, true) > 0), isnotnull(features#81)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      :     +- HashAggregate(keys=[COMM_Clean#234], functions=[count(DR_NO#24)], schema specialized)\n",
      "      :        +- Exchange hashpartitioning(COMM_Clean#234, 1000), ENSURE_REQUIREMENTS, [plan_id=187]\n",
      "      :           +- HashAggregate(keys=[COMM_Clean#234], functions=[partial_count(DR_NO#24)], schema specialized)\n",
      "      :              +- Project [DR_NO#24, upper(trim(COMM#168, None)) AS COMM_Clean#234]\n",
      "      :                 +- RangeJoin geometry_point#135: geometry, geometry#92: geometry, WITHIN\n",
      "      :                    :- Project [DR_NO#24,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry_point#135]\n",
      "      :                    :  +- Filter (((((isnotnull(LAT#50) AND isnotnull(LON#51)) AND NOT (LAT#50 = 0.0)) AND NOT (LON#51 = 0.0)) AND year(cast(gettimestamp(DATE OCC#26, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "      :                    :     +- FileScan csv [DR_NO#24,DATE OCC#26,LAT#50,LON#51] Batched: false, DataFilters: [isnotnull(LAT#50), isnotnull(LON#51), NOT (LAT#50 = 0.0), NOT (LON#51 = 0.0), year(cast(gettimes..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))], ReadSchema: struct<DR_NO:int,DATE OCC:string,LAT:float,LON:float>\n",
      "      :                    +- Project [features#89.geometry AS geometry#92, features#89.properties.COMM AS COMM#168]\n",
      "      :                       +- Filter (isnotnull(features#89.geometry) AND isnotnull(upper(trim(features#89.properties.COMM, None))))\n",
      "      :                          +- Generate explode(features#265), false, [features#89]\n",
      "      :                             +- Filter ((size(features#265, true) > 0) AND isnotnull(features#265))\n",
      "      :                                +- FileScan geojson [features#265] Batched: false, DataFilters: [(size(features#265, true) > 0), isnotnull(features#265)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=196]\n",
      "         +- HashAggregate(keys=[Community_Clean#215], functions=[avg(Median_Income#175)], schema specialized)\n",
      "            +- Exchange hashpartitioning(Community_Clean#215, 1000), ENSURE_REQUIREMENTS, [plan_id=193]\n",
      "               +- HashAggregate(keys=[Community_Clean#215], functions=[partial_avg(Median_Income#175)], schema specialized)\n",
      "                  +- Project [upper(trim(Community_Clean#212, None)) AS Community_Clean#215, Median_Income#175]\n",
      "                     +- Generate explode(comm_array#202), [Median_Income#175], false, [Community_Clean#212]\n",
      "                        +- Project [cast(regexp_replace(Estimated Median Income#100, [$,], , 1) as int) AS Median_Income#175, split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1) AS comm_array#202]\n",
      "                           +- Filter (((isnotnull(Estimated Median Income#100) AND isnotnull(cast(regexp_replace(Estimated Median Income#100, [$,], , 1) as int))) AND (size(split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1), true) > 0)) AND isnotnull(split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1)))\n",
      "                              +- FileScan csv [Community#99,Estimated Median Income#100] Batched: false, DataFilters: [isnotnull(Estimated Median Income#100), isnotnull(cast(regexp_replace(Estimated Median Income#10..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [IsNotNull(Estimated Median Income)], ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "Execution Time: 28.1783 seconds\n",
      "Correlation (All Communities): -0.16511958714592517\n",
      "Correlation (Top 10 & Bottom 10 Income Areas): -0.22162106566579637\n",
      "\n",
      "--- Top 10 Wealthiest Areas Stats ---\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|             COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|PACIFIC PALISADES|           20952|           1362|     212115.0|                 0.03250|\n",
      "|      PLAYA VISTA|           16230|           1294|     166667.0|                 0.03986|\n",
      "|        BRENTWOOD|           30334|           2145|     143000.0|                 0.03536|\n",
      "|   MARINA DEL REY|           11373|             67|     137813.0|                 0.00295|\n",
      "| MARINA PENINSULA|            4903|            472|     137813.0|                 0.04813|\n",
      "|     PORTER RANCH|           35717|           1395|     130322.0|                 0.01953|\n",
      "|           ENCINO|           45045|           3893|     118878.0|                 0.04321|\n",
      "|      WESTCHESTER|           50760|           7592|     115943.0|                 0.07478|\n",
      "|    PLAYA DEL REY|            2958|            378|     110884.0|                 0.06389|\n",
      "|     CENTURY CITY|           13600|           1376|     109704.0|                 0.05059|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "\n",
      "\n",
      "--- Top 10 Poorest Areas Stats ---\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "|            COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "| HARVARD HEIGHTS|           15806|           1754|      41068.0|                 0.05549|\n",
      "|       KOREATOWN|           47297|           5330|      42990.5|                 0.05635|\n",
      "|        WESTLAKE|           56428|           7579|      43796.0|                 0.06716|\n",
      "|           WATTS|           42246|           4782|      46920.5|                 0.05660|\n",
      "|   BALDWIN HILLS|           30096|           3847|      49379.0|                 0.06391|\n",
      "|          LENNOX|           20323|             20|      50052.0|                 0.00049|\n",
      "|  EAST HOLLYWOOD|           24474|           2908|      50822.0|                 0.05941|\n",
      "|   PANORAMA CITY|           69747|           5112|      51485.0|                 0.03665|\n",
      "|    LEIMERT PARK|           15827|           2052|      52327.0|                 0.06483|\n",
      "|EAST LOS ANGELES|          118771|             54|      52878.5|                 0.00023|\n",
      "+----------------+----------------+---------------+-------------+------------------------+"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPARING CRIME DATA (2020-2021) ---\n",
    "# Filtering for years 2020-2021 Null Island (0,0) erasing\n",
    "crimes_filtered = Crime_df.filter((col(\"LAT\") != 0) & (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"Year\", year(to_date(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))) \\\n",
    "    .filter(col(\"Year\").isin([2020, 2021])) \\\n",
    "    .withColumn(\"geometry_point\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"DR_NO\", \"geometry_point\")\n",
    "\n",
    "# --- 2. PREPARING CENSUS DATA ---\n",
    "# We use POP20 (Population) and COMM (Location)\n",
    "census_blocks = blocks_df.select(\n",
    "    col(\"geometry\"),\n",
    "    col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    col(\"properties.POP20\").alias(\"POP20\")\n",
    ").filter(col(\"geometry\").isNotNull())\n",
    "\n",
    "# --- 3. PREPARING INCOME DATA ---\n",
    "income_clean = income_df.withColumn(\"Median_Income\", regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(IntegerType())) \\\n",
    "    .filter(col(\"Median_Income\").isNotNull()) \\\n",
    "    .withColumn(\"raw_comm\", col(\"Community\")) \\\n",
    "    .withColumn(\"comm_fixed_la\", regexp_replace(col(\"raw_comm\"), \"Los Angeles \\\\((.*?)\\\\)\", \"$1\")) \\\n",
    "    .withColumn(\"comm_final_str\", regexp_replace(col(\"comm_fixed_la\"), \"\\\\s*\\\\(.*?\\\\)\", \"\")) \\\n",
    "    .withColumn(\"comm_array\", split(col(\"comm_final_str\"), \",\")) \\\n",
    "    .select(explode(col(\"comm_array\")).alias(\"Community_Clean\"), col(\"Median_Income\")) \\\n",
    "    .withColumn(\"Community_Clean\", upper(trim(col(\"Community_Clean\")))) \\\n",
    "    .groupBy(\"Community_Clean\") \\\n",
    "    .agg(avg(\"Median_Income\").alias(\"Median_Income\"))\n",
    "\n",
    "# --- 4. SPATIAL JOIN (CRIMES + CENSUS) ---\n",
    "# We find in which Census block each crime is registered\n",
    "spatial_join = crimes_filtered.alias(\"crimes\").join(\n",
    "    census_blocks.alias(\"blocks\"),\n",
    "    expr(\"ST_Contains(blocks.geometry, crimes.geometry_point)\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# --- 5. AGGREGATIONS (PER COMMUNITY) ---\n",
    "# Step Α: Counting crimes per COMM\n",
    "crimes_per_comm = spatial_join.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(count(\"DR_NO\").alias(\"Total_Crimes_2y\"))\n",
    "\n",
    "# Step Β: Summing the population per COMM\n",
    "pop_per_comm = census_blocks.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(_sum(\"POP20\").alias(\"Total_Population\")) \\\n",
    "    .filter(col(\"Total_Population\") > 0)\n",
    "\n",
    "# Step C: Merging (Metrics + Income)\n",
    "# Join 'Community' and 'COMM'\n",
    "final_stats = pop_per_comm.join(crimes_per_comm, \"COMM_Clean\", \"inner\") \\\n",
    "    .join(income_clean, pop_per_comm.COMM_Clean == income_clean.Community_Clean, \"inner\") \\\n",
    "    .select(\n",
    "        col(\"COMM_Clean\").alias(\"COMM\"),\n",
    "        col(\"Total_Population\"),\n",
    "        col(\"Total_Crimes_2y\"),\n",
    "        col(\"Median_Income\")\n",
    "    )\n",
    "\n",
    "# --- 6. CALCULATE FINAL METRIC ---\n",
    "# Annual average crimes per person:\n",
    "# (Total_Crimes / 2) / Total_Population\n",
    "final_stats = final_stats.withColumn(\n",
    "    \"Crimes_Per_Person_Yearly\",\n",
    "    (col(\"Total_Crimes_2y\") / 2) / col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Join explain\n",
    "final_stats.explain()\n",
    "\n",
    "# Time Benchmarking\n",
    "start_time = time.time()\n",
    "total_records = final_stats.count()\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# --- 7. CORRELATION CALCULATIONS ---\n",
    "# 7.1 All Blocks\n",
    "corr_all = final_stats.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (All Communities): {corr_all}\")\n",
    "\n",
    "# 7.2 Top 10 and Bottom 10 based on income\n",
    "top_10 = final_stats.orderBy(col(\"Median_Income\").desc()).limit(10)\n",
    "bottom_10 = final_stats.orderBy(col(\"Median_Income\").asc()).limit(10)\n",
    "\n",
    "# Merge\n",
    "subset_extremes = top_10.union(bottom_10)\n",
    "\n",
    "corr_extremes = subset_extremes.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (Top 10 & Bottom 10 Income Areas): {corr_extremes}\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Top 10 Wealthiest Areas Stats ---\")\n",
    "top_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()\n",
    "print(\"\\n--- Top 10 Poorest Areas Stats ---\")\n",
    "bottom_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7414931-66ec-476b-a1b8-ce4f1d9f91c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '8', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>478</td><td>application_1764662801237_0480</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0480/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-11.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0480_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>482</td><td>application_1764662801237_0484</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0484/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-75.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0484_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>485</td><td>application_1764662801237_0487</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0487/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0487_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>486</td><td>application_1764662801237_0488</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0488/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-85.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0488_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>492</td><td>application_1764662801237_0494</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0494/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-65.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0494_01_000002/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"8\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a752f20a-b0dd-43af-ad93-09156cee9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>494</td><td>application_1764662801237_0496</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1764662801237_0496/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-172.eu-central-1.compute.internal:8042/node/containerlogs/container_1764662801237_0496_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a65230bfe8e4916875bce2058d74ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4509b6ea03344103bd97c7bf6d90d862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_date, count, sum as _sum, corr, desc, lit, avg, regexp_replace, expr, upper, trim, split, explode, format_number\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, DoubleType, FloatType\n",
    "import time\n",
    "\n",
    "# Sedona Imports\n",
    "from sedona.spark.SedonaContext import SedonaContext\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Query 5 execution 3\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.sedona_sql.io.SedonaSqlWrapper\") \\\n",
    "    .getOrCreate()\n",
    "spark = SedonaContext.create(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92e0156-8c45-44bf-9db5-44021f8bed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd4128c088f416cbf245e33901e53e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing the data\n",
    "Crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", FloatType()),\n",
    "    StructField(\"LON\", FloatType()),\n",
    "])\n",
    "\n",
    "Income_schema = StructType([\n",
    "    StructField(\"Zip Code\", IntegerType()),\n",
    "    StructField(\"Community\", StringType()),\n",
    "    StructField(\"Estimated Median Income\", StringType()),\n",
    "])\n",
    "\n",
    "Crime_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                          header = True, \\\n",
    "                          schema = Crime_data_schema)\n",
    "\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\") \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "income_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\", \\\n",
    "                           header = True, \\\n",
    "                           schema = Income_schema, \\\n",
    "                           sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d461d5-5fbd-4cdf-bfce-901f256e0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacf35cd21b94acbb7b3db5f11caf111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [COMM_Clean#251 AS COMM#282, Total_Population#261L, Total_Crimes_2y#248L, Median_Income#221, ((cast(Total_Crimes_2y#248L as double) / 2.0) / cast(Total_Population#261L as double)) AS Crimes_Per_Person_Yearly#287]\n",
      "   +- BroadcastHashJoin [COMM_Clean#251], [Community_Clean#215], Inner, BuildRight, false\n",
      "      :- Project [COMM_Clean#251, Total_Population#261L, Total_Crimes_2y#248L]\n",
      "      :  +- BroadcastHashJoin [COMM_Clean#251], [COMM_Clean#234], Inner, BuildLeft, false\n",
      "      :     :- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=190]\n",
      "      :     :  +- Filter (isnotnull(Total_Population#261L) AND (Total_Population#261L > 0))\n",
      "      :     :     +- HashAggregate(keys=[COMM_Clean#251], functions=[sum(POP20#169L)], schema specialized)\n",
      "      :     :        +- Exchange hashpartitioning(COMM_Clean#251, 1000), ENSURE_REQUIREMENTS, [plan_id=184]\n",
      "      :     :           +- HashAggregate(keys=[COMM_Clean#251], functions=[partial_sum(POP20#169L)], schema specialized)\n",
      "      :     :              +- Project [features#89.properties.POP20 AS POP20#169L, upper(trim(features#89.properties.COMM, None)) AS COMM_Clean#251]\n",
      "      :     :                 +- Filter (isnotnull(features#89.geometry) AND isnotnull(upper(trim(features#89.properties.COMM, None))))\n",
      "      :     :                    +- Generate explode(features#81), false, [features#89]\n",
      "      :     :                       +- Filter ((size(features#81, true) > 0) AND isnotnull(features#81))\n",
      "      :     :                          +- FileScan geojson [features#81] Batched: false, DataFilters: [(size(features#81, true) > 0), isnotnull(features#81)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      :     +- HashAggregate(keys=[COMM_Clean#234], functions=[count(DR_NO#24)], schema specialized)\n",
      "      :        +- Exchange hashpartitioning(COMM_Clean#234, 1000), ENSURE_REQUIREMENTS, [plan_id=187]\n",
      "      :           +- HashAggregate(keys=[COMM_Clean#234], functions=[partial_count(DR_NO#24)], schema specialized)\n",
      "      :              +- Project [DR_NO#24, upper(trim(COMM#168, None)) AS COMM_Clean#234]\n",
      "      :                 +- RangeJoin geometry_point#135: geometry, geometry#92: geometry, WITHIN\n",
      "      :                    :- Project [DR_NO#24,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry_point#135]\n",
      "      :                    :  +- Filter (((((isnotnull(LAT#50) AND isnotnull(LON#51)) AND NOT (LAT#50 = 0.0)) AND NOT (LON#51 = 0.0)) AND year(cast(gettimestamp(DATE OCC#26, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) IN (2020,2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "      :                    :     +- FileScan csv [DR_NO#24,DATE OCC#26,LAT#50,LON#51] Batched: false, DataFilters: [isnotnull(LAT#50), isnotnull(LON#51), NOT (LAT#50 = 0.0), NOT (LON#51 = 0.0), year(cast(gettimes..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0))], ReadSchema: struct<DR_NO:int,DATE OCC:string,LAT:float,LON:float>\n",
      "      :                    +- Project [features#89.geometry AS geometry#92, features#89.properties.COMM AS COMM#168]\n",
      "      :                       +- Filter (isnotnull(features#89.geometry) AND isnotnull(upper(trim(features#89.properties.COMM, None))))\n",
      "      :                          +- Generate explode(features#265), false, [features#89]\n",
      "      :                             +- Filter ((size(features#265, true) > 0) AND isnotnull(features#265))\n",
      "      :                                +- FileScan geojson [features#265] Batched: false, DataFilters: [(size(features#265, true) > 0), isnotnull(features#265)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=196]\n",
      "         +- HashAggregate(keys=[Community_Clean#215], functions=[avg(Median_Income#175)], schema specialized)\n",
      "            +- Exchange hashpartitioning(Community_Clean#215, 1000), ENSURE_REQUIREMENTS, [plan_id=193]\n",
      "               +- HashAggregate(keys=[Community_Clean#215], functions=[partial_avg(Median_Income#175)], schema specialized)\n",
      "                  +- Project [upper(trim(Community_Clean#212, None)) AS Community_Clean#215, Median_Income#175]\n",
      "                     +- Generate explode(comm_array#202), [Median_Income#175], false, [Community_Clean#212]\n",
      "                        +- Project [cast(regexp_replace(Estimated Median Income#100, [$,], , 1) as int) AS Median_Income#175, split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1) AS comm_array#202]\n",
      "                           +- Filter (((isnotnull(Estimated Median Income#100) AND isnotnull(cast(regexp_replace(Estimated Median Income#100, [$,], , 1) as int))) AND (size(split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1), true) > 0)) AND isnotnull(split(regexp_replace(regexp_replace(Community#99, Los Angeles \\((.*?)\\), $1, 1), \\s*\\(.*?\\), , 1), ,, -1)))\n",
      "                              +- FileScan csv [Community#99,Estimated Median Income#100] Batched: false, DataFilters: [isnotnull(Estimated Median Income#100), isnotnull(cast(regexp_replace(Estimated Median Income#10..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [IsNotNull(Estimated Median Income)], ReadSchema: struct<Community:string,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "Execution Time: 41.3967 seconds\n",
      "Correlation (All Communities): -0.16511958714592512\n",
      "Correlation (Top 10 & Bottom 10 Income Areas): -0.22162106566579637\n",
      "\n",
      "--- Top 10 Wealthiest Areas Stats ---\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|             COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "|PACIFIC PALISADES|           20952|           1362|     212115.0|                 0.03250|\n",
      "|      PLAYA VISTA|           16230|           1294|     166667.0|                 0.03986|\n",
      "|        BRENTWOOD|           30334|           2145|     143000.0|                 0.03536|\n",
      "|   MARINA DEL REY|           11373|             67|     137813.0|                 0.00295|\n",
      "| MARINA PENINSULA|            4903|            472|     137813.0|                 0.04813|\n",
      "|     PORTER RANCH|           35717|           1395|     130322.0|                 0.01953|\n",
      "|           ENCINO|           45045|           3893|     118878.0|                 0.04321|\n",
      "|      WESTCHESTER|           50760|           7592|     115943.0|                 0.07478|\n",
      "|    PLAYA DEL REY|            2958|            378|     110884.0|                 0.06389|\n",
      "|     CENTURY CITY|           13600|           1376|     109704.0|                 0.05059|\n",
      "+-----------------+----------------+---------------+-------------+------------------------+\n",
      "\n",
      "\n",
      "--- Top 10 Poorest Areas Stats ---\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "|            COMM|Total_Population|Total_Crimes_2y|Median_Income|Crimes_Per_Person_Yearly|\n",
      "+----------------+----------------+---------------+-------------+------------------------+\n",
      "| HARVARD HEIGHTS|           15806|           1754|      41068.0|                 0.05549|\n",
      "|       KOREATOWN|           47297|           5330|      42990.5|                 0.05635|\n",
      "|        WESTLAKE|           56428|           7579|      43796.0|                 0.06716|\n",
      "|           WATTS|           42246|           4782|      46920.5|                 0.05660|\n",
      "|   BALDWIN HILLS|           30096|           3847|      49379.0|                 0.06391|\n",
      "|          LENNOX|           20323|             20|      50052.0|                 0.00049|\n",
      "|  EAST HOLLYWOOD|           24474|           2908|      50822.0|                 0.05941|\n",
      "|   PANORAMA CITY|           69747|           5112|      51485.0|                 0.03665|\n",
      "|    LEIMERT PARK|           15827|           2052|      52327.0|                 0.06483|\n",
      "|EAST LOS ANGELES|          118771|             54|      52878.5|                 0.00023|\n",
      "+----------------+----------------+---------------+-------------+------------------------+"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPARING CRIME DATA (2020-2021) ---\n",
    "# Filtering for years 2020-2021 Null Island (0,0) erasing\n",
    "crimes_filtered = Crime_df.filter((col(\"LAT\") != 0) & (col(\"LON\") != 0)) \\\n",
    "    .withColumn(\"Year\", year(to_date(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))) \\\n",
    "    .filter(col(\"Year\").isin([2020, 2021])) \\\n",
    "    .withColumn(\"geometry_point\", expr(\"ST_Point(LON, LAT)\")) \\\n",
    "    .select(\"DR_NO\", \"geometry_point\")\n",
    "\n",
    "# --- 2. PREPARING CENSUS DATA ---\n",
    "# We use POP20 (Population) and COMM (Location)\n",
    "census_blocks = blocks_df.select(\n",
    "    col(\"geometry\"),\n",
    "    col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    col(\"properties.POP20\").alias(\"POP20\")\n",
    ").filter(col(\"geometry\").isNotNull())\n",
    "\n",
    "# --- 3. PREPARING INCOME DATA ---\n",
    "income_clean = income_df.withColumn(\"Median_Income\", regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(IntegerType())) \\\n",
    "    .filter(col(\"Median_Income\").isNotNull()) \\\n",
    "    .withColumn(\"raw_comm\", col(\"Community\")) \\\n",
    "    .withColumn(\"comm_fixed_la\", regexp_replace(col(\"raw_comm\"), \"Los Angeles \\\\((.*?)\\\\)\", \"$1\")) \\\n",
    "    .withColumn(\"comm_final_str\", regexp_replace(col(\"comm_fixed_la\"), \"\\\\s*\\\\(.*?\\\\)\", \"\")) \\\n",
    "    .withColumn(\"comm_array\", split(col(\"comm_final_str\"), \",\")) \\\n",
    "    .select(explode(col(\"comm_array\")).alias(\"Community_Clean\"), col(\"Median_Income\")) \\\n",
    "    .withColumn(\"Community_Clean\", upper(trim(col(\"Community_Clean\")))) \\\n",
    "    .groupBy(\"Community_Clean\") \\\n",
    "    .agg(avg(\"Median_Income\").alias(\"Median_Income\"))\n",
    "\n",
    "# --- 4. SPATIAL JOIN (CRIMES + CENSUS) ---\n",
    "# We find in which Census block each crime is registered\n",
    "spatial_join = crimes_filtered.alias(\"crimes\").join(\n",
    "    census_blocks.alias(\"blocks\"),\n",
    "    expr(\"ST_Contains(blocks.geometry, crimes.geometry_point)\"),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# --- 5. AGGREGATIONS (PER COMMUNITY) ---\n",
    "# Step Α: Counting crimes per COMM\n",
    "crimes_per_comm = spatial_join.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(count(\"DR_NO\").alias(\"Total_Crimes_2y\"))\n",
    "\n",
    "# Step Β: Summing the population per COMM\n",
    "pop_per_comm = census_blocks.withColumn(\"COMM_Clean\", upper(trim(col(\"COMM\")))) \\\n",
    "    .groupBy(\"COMM_Clean\") \\\n",
    "    .agg(_sum(\"POP20\").alias(\"Total_Population\")) \\\n",
    "    .filter(col(\"Total_Population\") > 0)\n",
    "\n",
    "# Step C: Merging (Metrics + Income)\n",
    "# Join 'Community' and 'COMM'\n",
    "final_stats = pop_per_comm.join(crimes_per_comm, \"COMM_Clean\", \"inner\") \\\n",
    "    .join(income_clean, pop_per_comm.COMM_Clean == income_clean.Community_Clean, \"inner\") \\\n",
    "    .select(\n",
    "        col(\"COMM_Clean\").alias(\"COMM\"),\n",
    "        col(\"Total_Population\"),\n",
    "        col(\"Total_Crimes_2y\"),\n",
    "        col(\"Median_Income\")\n",
    "    )\n",
    "\n",
    "# --- 6. CALCULATE FINAL METRIC ---\n",
    "# Annual average crimes per person:\n",
    "# (Total_Crimes / 2) / Total_Population\n",
    "final_stats = final_stats.withColumn(\n",
    "    \"Crimes_Per_Person_Yearly\",\n",
    "    (col(\"Total_Crimes_2y\") / 2) / col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Join explain\n",
    "final_stats.explain()\n",
    "\n",
    "# Time Benchmarking\n",
    "start_time = time.time()\n",
    "total_records = final_stats.count()\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# --- 7. CORRELATION CALCULATIONS ---\n",
    "# 7.1 All Blocks\n",
    "corr_all = final_stats.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (All Communities): {corr_all}\")\n",
    "\n",
    "# 7.2 Top 10 and Bottom 10 based on income\n",
    "top_10 = final_stats.orderBy(col(\"Median_Income\").desc()).limit(10)\n",
    "bottom_10 = final_stats.orderBy(col(\"Median_Income\").asc()).limit(10)\n",
    "\n",
    "# Merge\n",
    "subset_extremes = top_10.union(bottom_10)\n",
    "\n",
    "corr_extremes = subset_extremes.stat.corr(\"Median_Income\", \"Crimes_Per_Person_Yearly\")\n",
    "print(f\"Correlation (Top 10 & Bottom 10 Income Areas): {corr_extremes}\")\n",
    "\n",
    "# Visualization\n",
    "print(\"\\n--- Top 10 Wealthiest Areas Stats ---\")\n",
    "top_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()\n",
    "print(\"\\n--- Top 10 Poorest Areas Stats ---\")\n",
    "bottom_10.withColumn(\"Crimes_Per_Person_Yearly\", format_number(\"Crimes_Per_Person_Yearly\", 5)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
